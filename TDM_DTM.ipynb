{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit_learn\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\kush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit_learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit_learn)\n",
      "  Downloading scipy-1.14.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit_learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit_learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "   ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.9/10.9 MB 18.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/10.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/10.9 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.9/10.9 MB 16.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.0-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 3.1/44.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 8.4/44.5 MB 21.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.1/44.5 MB 19.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 15.7/44.5 MB 19.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.7/44.5 MB 20.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.2/44.5 MB 20.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.1/44.5 MB 20.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.6/44.5 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.5/44.5 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.5 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit_learn\n",
      "Successfully installed scikit_learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Document Matrix (TDM) / Document-Term Matrix (DTM):\n",
      "   algorithms  an  aspect  data  field  important  interdisciplinary  is  \\\n",
      "0           0   1       0     1      1          0                  1   1   \n",
      "1           0   0       0     1      0          0                  0   1   \n",
      "2           1   0       0     1      0          0                  0   0   \n",
      "3           0   1       1     1      0          1                  0   1   \n",
      "\n",
      "   learning  machine  of  science  statistics  subset  uses  \n",
      "0         0        0   0        1           0       0     0  \n",
      "1         1        1   1        1           0       1     0  \n",
      "2         1        1   0        1           0       0     1  \n",
      "3         0        0   1        1           1       0     0  \n",
      "\n",
      "\n",
      "TF_IDF Matrix:\n",
      "   algorithms        an   aspect      data     field  important  \\\n",
      "0    0.000000  0.417059  0.00000  0.276047  0.528987    0.00000   \n",
      "1    0.000000  0.000000  0.00000  0.267108  0.000000    0.00000   \n",
      "2    0.513813  0.000000  0.00000  0.268129  0.000000    0.00000   \n",
      "3    0.000000  0.345900  0.43873  0.228948  0.000000    0.43873   \n",
      "\n",
      "   interdisciplinary        is  learning   machine        of   science  \\\n",
      "0           0.528987  0.337645  0.000000  0.000000  0.000000  0.276047   \n",
      "1           0.000000  0.326712  0.403554  0.403554  0.403554  0.267108   \n",
      "2           0.000000  0.000000  0.405096  0.405096  0.000000  0.268129   \n",
      "3           0.000000  0.280036  0.000000  0.000000  0.345900  0.228948   \n",
      "\n",
      "   statistics    subset      uses  \n",
      "0     0.00000  0.000000  0.000000  \n",
      "1     0.00000  0.511857  0.000000  \n",
      "2     0.00000  0.000000  0.513813  \n",
      "3     0.43873  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
    "import pandas as pd\n",
    "\n",
    "#sample\n",
    "documents = [\n",
    "    \"Data science is an interdisciplinary field.\",\n",
    "    \"Machine Learning is a subset of data science.\",\n",
    "    \"Data science uses machine learning algorithms.\",\n",
    "    \"Statistics is an important aspect of data science.\"\n",
    "]\n",
    "\n",
    "#Creating a CountVectorizer object to count word frequencies\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "#Generating the Term-Document Matrix (TDM) / Documnet_Term Matrix (DTM)\n",
    "#The matrix contains the frequency of each word in ecah document\n",
    "#Here  , the TDM and DTM are the same; the naming depends on the context.\n",
    "term_document_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "#Convert the matrix to a Data FRame for better viualization.\n",
    "tdm_df = pd.DataFrame(term_document_matrix.toarray() , columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "#Print the Term-Document Matrix\n",
    "print(\"Term-Document Matrix (TDM) / Document-Term Matrix (DTM):\")\n",
    "print(tdm_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Explaination\n",
    "#Rows represent documents, and columns represent terms(words).\n",
    "#Each cell (i,j) contain the frequency of the word j in document i.\n",
    "\n",
    "#Applying TF-IDF transformation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(term_document_matrix)\n",
    "\n",
    "#Convert the TF-IDF matrix to a DataFramefor better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray() , columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "#Print the TF_IDF Matrix\n",
    "print(\"TF_IDF Matrix:\")\n",
    "print(tfidf_df)\n",
    "\n",
    "#Explanation:\n",
    "#TF_IDF (Term Frequency-Incerse Document Frequency) normalizes the word frequencies\n",
    "#by accountingfor the frequency of the word across all documents.\n",
    "# This helps in reducing the impact of common words and highlighting important words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: afinn in c:\\users\\kush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text = This product is absolutely amazing and I love using it!\n",
      "Sentiment_score : 7.0\n",
      "sentiment_Type : Positive\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "text = \"This product is absolutely amazing and I love using it!\"\n",
    "\n",
    "sentiment_score = afinn.score(text)\n",
    "\n",
    "if sentiment_score > 0:\n",
    "    sentiment_type = 'Positive'\n",
    "elif sentiment_score < 0:\n",
    "    sentiment_type = 'Negative'\n",
    "else:\n",
    "    sentiment_type = 'Neutral'\n",
    "\n",
    "print(f'Text = {text}')\n",
    "print(f\"Sentiment_score : {sentiment_score}\")\n",
    "print(f\"sentiment_Type : {sentiment_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

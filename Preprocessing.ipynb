{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04eb40a",
   "metadata": {
    "id": "c04eb40a"
   },
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eBttIpMMmbW",
   "metadata": {
    "id": "7eBttIpMMmbW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "z4CsUptQMtZM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4CsUptQMtZM",
    "outputId": "ad748279-da46-4e58-ddab-dc3d7b4ab9d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sahilchavan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sahilchavan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#download necesary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zVhgrVRjMt2D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVhgrVRjMt2D",
    "outputId": "44c58623-5fa3-44b3-86c6-61306956a80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original words : ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', '.', 'As', 'a', 'computer', 'science', 'discipline', ',', 'NLP', 'is', 'concerned', 'with', 'the', 'design', 'of', 'natural', 'language', 'processing', 'systems', ':', 'software', 'systems', 'that', 'are', 'able', 'to', 'read', ',', 'understand', ',', 'and', 'produce', 'human', 'language', '.']\n",
      "filtered words : ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', '(', 'natural', ')', 'languages', '.', 'As', 'computer', 'science', 'discipline', ',', 'NLP', 'concerned', 'design', 'natural', 'language', 'processing', 'systems', ':', 'software', 'systems', 'able', 'read', ',', 'understand', ',', 'produce', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "# prompt: create a corpus in a paragraph\n",
    "\n",
    "paragraph = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages.\n",
    "As a computer science discipline, NLP is concerned with the design of natural language processing systems: software systems that are able to read, understand, and produce human language.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the paragraph into words.\n",
    "words = word_tokenize(paragraph)\n",
    "\n",
    "# Remove stop words.\n",
    "filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "print(\"original words :\",words)\n",
    "print(\"filtered words :\",filtered_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "SoZG0g9SMuIE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SoZG0g9SMuIE",
    "outputId": "095aa2cd-7257-4a5c-bafc-087b3a9ad98a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sahilchavan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#download the data\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b5d18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sahilchavan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "MrxLbZXASPxU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrxLbZXASPxU",
    "outputId": "f4c8ddc2-2f64-4ae4-bc6e-3b6159d88beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed words: ['comput', 'scienc', 'natur', 'languag', 'process', 'swim', 'leav', 'gees', 'gener']\n",
      "Lemmatized words: ['computer', 'science', 'natural', 'language', 'processing', 'swimming', 'leaf', 'goose', 'generously']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_words = [\"computer\", \"science\", \"natural\", \"language\", \"processing\",\"swimming\",\"leaves\",\"geese\",\"generously\"]\n",
    "\n",
    "# Stem the words.\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in random_words]\n",
    "\n",
    "# Lemmatize the words.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in random_words]\n",
    "\n",
    "# Print the stemmed and lemmatized words.\n",
    "print(\"Stemmed words:\", stemmed_words)\n",
    "print(\"Lemmatized words:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xe0c--SdSQJx",
   "metadata": {
    "id": "Xe0c--SdSQJx"
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b9fbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sahilchavan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "C8lgng6-SSca",
   "metadata": {
    "id": "C8lgng6-SSca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal Text\n",
      "NLTK is a powerfeul library\n",
      "\n",
      "PoS tagging Result:\n",
      "\"NLTK\" is a NNP\n",
      "\"is\" is a VBZ\n",
      "\"a\" is a DT\n",
      "\"powerfeul\" is a JJ\n",
      "\"library\" is a NN\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "#sample text\n",
    "text = \"NLTK is a powerfeul library\"\n",
    "\n",
    "#tokenize the corpus \n",
    "words = word_tokenize(text)\n",
    "\n",
    "#performing PoS tagging \n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "#Displaying the PoS tagged resuilts in sep lines\n",
    "print(\"Orignal Text\")\n",
    "print(text)\n",
    "\n",
    "print(\"\\nPoS tagging Result:\")\n",
    "for j,k in pos_tags:\n",
    "        print(f\"\\\"{j}\\\" is a {k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QYVAccSWSS5l",
   "metadata": {
    "id": "QYVAccSWSS5l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
